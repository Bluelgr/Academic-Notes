\documentclass{article}

\usepackage{amsmath,mathtools}
\usepackage{bm,extarrows,ulem}
\usepackage{mathrsfs}
\usepackage{geometry,graphicx,color}
\geometry{centering,scale=0.8}

\newcommand{\sect}{\section}
\newcommand{\subsec}{\subsection}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bs}{\be\begin{split}}

\newcommand{\dif}{\,\mathrm{d}}
\newcommand{\p}{\partial}
\newcommand{\1}{\left}
\newcommand{\2}{\right}
\newcommand{\ma}{\mathcal}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}

\newcommand{\m}{\mu}
\newcommand{\n}{\nu}
\newcommand{\al}{\alpha}
\newcommand{\bet}{\beta}
\newcommand{\lam}{\lambda}
\newcommand{\sig}{\sigma}
\newcommand{\ep}{\epsilon}
\newcommand{\om}{\omega}
\newcommand{\del}{\delta}


\title{Notes on The Theoretical Minimum\\
--- Quantum Mechanics}
\author{Gui-Rong Liang}

\begin{document}
\maketitle
\tableofcontents

\newpage

\section{Mathematical Foundations and Spins}
\subsection{Quantum states, operators, and Hermitian properties}
A quantum state is represented by a ket vector that can be decomposed using the orthogonal basis vectors,
\be
|A\ra=\sum_j \al_j|j\ra, \quad\text{with} \quad \al_j=\la j|A\ra,
\ee
where the coefficient $\al_j$ is a complex number. Thus
\be
|A\ra=\sum_j |j\ra \la j|A\ra \implies  \sum_j |j\ra \la j|=1.
\ee
The probability of measuring a state corresponding to a certain basis is given by
\be
P_j=\al_j^*\al_j=\la A |j\ra \la j|A\ra,
\ee
then the normalization of probability gives to 
\be
1=\sum_j P_j=\sum_j\la A |j\ra \la j|A\ra=\la A|A\ra.
\ee
So the general principle is the state of a system is represented by a unit vector.\\

Now we introduce the matrix representation of an operator, which turn a vector to another vector,
\be
M|A\ra=|B\ra.
\ee
If we decompose A and B into components on basis vectors, we can represent the above equation as,
\be
\sum_j M |j\ra \al_j=\sum_j \bet_j|j\ra,
\ee
multiplying the above by a basis bra, we have
\be
\sum_j \la k| M |j\ra \al_j=\sum_j \bet_j \la k|j\ra = \bet_k,
\ee
which is denoted by 
\be
\sum_j M_{kj} \al_j = \bet_k,
\ee
where $M_{ij}\equiv \la k|M|j\ra$ is matrix element of the operator.\\
We write the above as explicit matrix form (taking 2 dimension as an example) as
\be
\1(\ba{cc}M_{11}&M_{12}\\M_{21}&M_{22}\ea\2)\1(\ba{c}\al_1\\\al_2\ea\2)=\1(\ba{c}\bet_1\\\bet_2\ea\2).
\ee
Now we take its complex conjugate and make it a equation of row vectors,
\be
\1(\ba{cc}\al_1^*&\al_2^*\ea\2)\1(\ba{cc}M_{11}^*&M_{21}^*\\M_{12}^*&M_{22}^*\ea\2)=\1(\ba{cc}\bet^*_1&\bet^*_2\ea\2),
\ee
which can be represented by the bras notation,
\be
\la A|M^\dagger =\la B|,
\ee
where $M^\dagger$ is called the \textit{Hermitian conjugate} of $M$, with the elements of $M^\dagger$ is given by
\be
(M^\dagger)_{jk}=M^*_{kj}.
\ee
An Hermitian operator is an operator which equals to its own Hermitian conjugate,
\be
M=M^\dagger.
\ee
Physical observable quantities are represented by Hermitian operators, due to the fact that the eigenvalues of Hermitian operators are real. And further, eigenvectors of an Hermitian operator corresponding to different eigenvalues are orthogonal. Next we will prove this.\\
If
\be
L|\lam\ra=\lam|\lam\ra,
\ee
where $L$ is Hermitian, we have
\be
\lam^*\la\lam|\lam\ra=\la\lam|L^\dagger|\lam\ra=\la\lam|L|\lam\ra=\lam\la\lam|\lam\ra \implies \lam^*=\lam,
\ee
Thus $\lam$ is real. Then if
\be\1\{\begin{split}
L|\lam_1\ra&=\lam_1|\lam_1\ra \\
L|\lam_2\ra&=\lam_2|\lam_2\ra,
\end{split}\2.\ee
we have
\be
\lam_1\la\lam_1|\lam_2\ra=\la\lam_1|L|\lam_2\ra=\lam_2\la\lam_1|\lam_2\ra \implies (\lam_1-\lam_2)\la\lam_1|\lam_2\ra=0 \implies \la\lam_1|\lam_2\ra=0.
\ee
Even if eigenvectors of the same eigenvalue are not orthogonal, we can make it orthogonal by Gram-Schmidt procedure. Finally we can make all eigenvectors of an Hermitian operator orthogonal, thus they can be used as a basis for the vector space.\\

\subsection{Time evolution of states and expectation values}

In classical mechanics, if two identical isolated systems start out in different states, they stay in different states. It underlies the fact that information is never lost. The same is true in quantum mechanics, and even much stronger. The direct manifestation is that if two states are initially orthogonal, they remain orthogonal throughout the evolution, or \textit{conservation of orthogonality}.

We denote a state at time $t$ as $|\Psi(t)\ra$, which originates from the state at time $t=0$, $|\Psi(0)\ra$, by acting an \textit{time-evolution operator} $\hat U(t)$ on it,
\be
|\Psi(t)\ra=\hat U(t) |\Psi(0)\ra.
\ee
This equation reflects the fact that quantum evolution of states allows us to compute the probabilities of the outcomes of later experiments, in contract to the case in classical mechanics, classical determinism allows us to predict the results of experiments. 

Mathematically, the conservation of orthogonality tells us
\be
\la \Psi(0)|\Phi(0)\ra=0 \implies \la \Psi(t)|\Phi(t)\ra=\la \Psi(0)|\hat U^\dagger(t) \hat U(t)|\Phi(0)\ra=0,
\ee
if we choose $|\Psi(0)\ra$ and $|\Phi(0)\ra$ to be any two orthonormal basis of vectors $|i\ra$ and $|j\ra$, we could obtain a property of the evolution operator,
\be
\la i|j\ra =\delta_{ij} = \la i|\hat U^\dagger(t) \hat U(t)|j\ra \implies \hat U^\dagger(t) \hat U(t)=I,
\ee
with which the evolution operator satisfies is called \textit{unitary}.\\

\textit{Principle: The evolution of state-vectors with time is unitary.}\\

A direct consequence of the unitarity leads to a much stronger version of conservation of orthogonality --- \textit{conservation of overlaps},
\be
\la A(t)|B(t)\ra = \la A(0) |\hat U^\dagger(t)\hat U(t)|B(0)\ra = \la A(0)|B(0)\ra,
\ee
which says the inner product of $|A\ra$ and $|B\ra$ does not change with time, or the inner product is conserved. Thus superficially conservation of orthogonality is a special case of conservation of overlap, we have seen that conservation of orthogonality can lead to conservation of overlap, thus they are equivalent.\\

Time evolution is led by incremental changes, so it would be inspiring to study the evolution operator of an infinitesimal time interval $\epsilon$. Another property besides unitarity that an evolution operator should have is \textit{continuity}, which means that the state-vector changes smoothly, or to be more explicitly, when $\epsilon$ is very small, $\hat U(\epsilon)$ is close to the unit operator, only differing from it by something of order $\epsilon$, and when $\ep$ is taken to be zero, the state does not change. 
\be
U(\epsilon)=I-i\epsilon H,
\ee
where the $-i$ and the operator $H$ is arbitrary and conventional. By plugging its Hermitian conjugate form
\be
U^\dagger(\epsilon)=I+i\epsilon H^\dagger
\ee
into the unitarity equation and expanding it to the first power, we have
\be
I=U^\dagger(\epsilon)U(\epsilon)=(I+i\epsilon H^\dagger)(I-i\epsilon H)=I+i\epsilon (H^\dagger-H),
\ee
or
\be
H^\dagger=H.
\ee
This Hermitian property of  $H$ has the great significance that $H$ is an observable and has a complete set of orthonormal eigenvalues and eigenvectors.\\

{\color{blue}Here I want to explain the above ansatz in more detail, which is due to my own understanding and I think is more natural.\\
The most general form of a state obtained by acting the infinitesimal evolution operator on the initial state, considering continuity, takes the form as
\be
U(\ep)|\Psi\ra=|\Psi\ra+\ep|\Theta\ra,
\ee
where $|\Theta\ra$ is some unknown state though, it can be obtained by acting some operator to the original state $|\Theta\ra\equiv A|\Psi\ra$, so we have
\be
U(\ep)|\Psi\ra=|\Psi\ra+\ep A|\Psi\ra =(I+\ep A)|\Psi\ra,
\ee
then we have a form of $U(\ep)$ as
\be
U(\epsilon)=I+\ep A,
\ee
where the property and meaning of $A$ is to be explored. Using the unitarity, we have
\be
I=U^\dagger(\epsilon)U(\epsilon)=(I+\ep A^\dagger)(I+\ep A)=I+\epsilon (A^\dagger+A),
\ee
or
\be
A^\dagger=-A,
\ee
which says $A$ is anti-Hermitian.\\
We argue that any operator can be make up of two Hermitian operator $F$ and $H$, which serve as real and imaginary part individually, as $A=F-iH$, (just take $F$ and $H$ as they have the same eigenvectors as $A$, and eigenvalues as real and imaginary part of the eigenvalues of $A$), then it's easy to figure out that an anti-Hermitian operator has no real part, i.e, $A=-iH$, thus we have the form of the infinitesimal evolution operator as
\be
U(\epsilon)=I-i\epsilon H,
\ee
and due to the Hermitian property of $H$, it should be some kind of observable.\\}

Now we're going to explore more on the evolution of states at an infinitesimal time interval $\epsilon$, we write
\be
|\Psi(\ep)\ra=\hat U(\ep) |\Psi(0)\ra = |\Psi(0)\ra-i\ep H|\Psi(0)\ra,
\ee
and rearranging this we have
\be
\frac{|\Psi(\ep)\ra-|\Psi(0)\ra}{\ep}=-iH|\Psi(0)\ra,
\ee
where the LHS is nothing but the time derivative of the state $|\Psi\ra$ at time $t=0$, but since the evolution is assumed to be linear, this should hold at any time $t$, so we may write
\be
\frac{\dif |\Psi\ra}{\dif t}=-i H|\Psi\ra,
\ee
where we wrote partial or total derivative make no difference. This equation tells us how an isolated (not contact with apparatus) state evolves with time, and it is called the \textit{generalized Schrodinger equation}. This is a simple first-order differential equation, and its solution is given by
\be
|\Psi(t)\ra=e^{-iHt}|\Psi(0)\ra,
\ee
thus we may extract the explicit form of the evolution operator as $U(t)=e^{-iHt}$, and we check it by taking the time to be infinitesimal time interval $\ep$,
\be
U(t)=e^{-iH\ep}\approx 1-iH\ep,
\ee
which is consistent with our previous reasoning.

As we proceed, we would discover that $H$ is nothing but the Hamiltonian operator, thus it has the dimension of energy. By checking the dimensionality of the time-dependent Schrodinger equation, we may fix it by a factor of $\hbar$, the Planck constant,
\be
i\hbar\frac{\p |\Psi\ra}{\p t}= H|\Psi\ra.
\ee
This is the standard form of the \textit{time-dependent Schrodinger equation}.\\

Now that we have derived that $H$ is a Hermitian operator, we can expand our states in the basis of $H$'s eigenvectors, to fully solve the Schrodinger equation,
\be
|\Psi\ra=\sum_j\al_j|E_j\ra,
\ee
where $|E_i\ra$ satisfies
\be
H|E_i\ra=E_i|E_i\ra,
\ee
and $E_i$s are the eigenvalues of $H$, or energy.\\
Using the time-dependent Schrodinger equation and due the fact that basis vector do not change with time, we have
\be
\sum_j\dot\al_j(t)|E_j\ra=-\frac i \hbar H\sum_j\al_j(t)|E_j\ra=-\frac i \hbar \sum_jE_j\al_j(t)|E_j\ra,
\ee
or regrouping
\be
\sum_j\bigg\{\dot\al_j(t)+\frac i \hbar E_j\al_j\bigg\}|E_j\ra=0,
\ee
thus every coefficient must be zero, and we have again the simplest differential equation,
\be\frac{\dif \al_j(t)}{\dif t}=-\frac i \hbar E_j \al_j(t)\ee,
and the solution is given by
\be\al_j(t)=\al_j(0)e^{-\frac i\hbar E_j t}\ee.
This equation contains the underlying assumption that Hamiltonian does not depend explicitly on time. And it's the first time for us to see the deep connection between energy and time.
We may extract out coefficients at time zero as \be\al_j(0)=\la E_j|\Psi(0)\ra\ee, thus we can write the full solution fo the time-dependent Schrodinger equation as
\be
|\Psi(t)\ra=\sum_j\al_j(0)e^{-\frac i\hbar E_jt}|E_j\ra=\sum_j|E_j\ra\la E_j|\Psi(0)\ra e^{-\frac i\hbar E_jt},
\ee
which emphasizes that we're summing over the basis vectors, and implies that as long as we have the initial state $|\Psi(0)\ra$ and the Hamiltonian $H$ which governs the physical law of evolution, we can have state $|\Psi(t)\ra$ at any time as we want.\\

The average, or expectation value, of an observable is the closest thing in quantum mechanics to a classical value. From a mathematical point of view, an average is defined by the equation
\be
\la\lam \ra = \sum_i \lam_i P(\lam_i).
\ee
If we expand a quantum state $|\Psi\ra$ in the orthonormal basis of eigenvectors of $L$,
\be
|\Psi\ra=\sum_i\al_i|\lam_i\ra,
\ee
we try to compute the following quantity,
\be
\la L \ra\equiv\la \Psi|L|\Psi\ra=\sum_i\sum_{j}\la \lam_j| \al^*_j \lam_i \al_i|\lam_i\ra=\sum_i  \lam_i (\al^*_i\al_i)= \sum_i \lam_i P(\lam_i)=\la \lam \ra,
\ee
that's why we use the notation $\la L\ra$ to denote the average. Let's see how this changes with time,
\bs
\frac\dif{\dif t}\la L \ra=\frac\dif{\dif t}\la \Psi(t)|L|\Psi(t)\ra&=\la \dot\Psi(t)|L|\Psi(t)\ra+\la \Psi(t)|L|\dot\Psi(t)\ra\\
&=\frac i \hbar \la \Psi(t)|(HL-LH)|\Psi(t)\ra=\frac i \hbar\la [H,L]\ra,
\end{split}\ee
where in the second row we used the Schrodinger equation, and the notation for a commutator. Note that the $i$ before the commutator is important, since the commutator itself is always imaginary.\\
Equivalently we rewrite it in a shorthand form:
\be\label{dl}
\frac{\dif L}{\dif t}=-\frac i \hbar [L,H],
\ee
where letters denote their average value. This is a very interesting and important equation. It relates the time derivative of the expectation value of an observable $L$ to the expectation value of another observable $[L,H]$. If we assume that the probabilities are nice, narrow, bell-shaped curves, this equation tells us how the peaks of the curves move with time. Equations like this are the closest thing in quantum mechanics to the equations of classical physics.\\
Recall that in classical mechanics, the time derivative of a physical quantity is given by its Poisson Bracket with the Hamiltonian,
\be
\frac{\dif L}{\dif t}=\{L,H\}.
\ee
Due to their similarity, we may identify a correspondence between the commutators and the Poisson Brackets,
\be
[L,H] \iff i\hbar\{L,H\}.
\ee
{\color{blue}Actually they have the same mathematical structures (like anti-symmetric, Bianchi identity) called the Lie Algebra, which would be explored later if we have time.}\\
In classical physics, commutators between ordinary observables are zero. But if we want to apply \eqref{dl} to classical physics, we must assume the commutators are not zero but a very small value of the order of $\hbar$. Vice versa, the classical limit is the limit at which $\hbar$ is negligibly small, thus the $i\hbar\{L,H\}$ goes back to the vanishing commutator.\\

Similar to classical mechanics, the equation tells us the expectation value of an observable $\la Q\ra$  does not change with time if it commutes with the Hamiltonian,
\be
\frac{\dif\bar Q}{\dif t}=-\frac i \hbar\overline{[Q,H]} =0.
\ee
Moreover if $Q$ commutes with the Hamiltonian, the expectation values of all powers of $Q$, and even all functions of $Q$ are conserved.\\
Just like in classical mechanics, the most obvious conserved quantity is the Hamiltonian itself, since it commutes with itself,
\be
\frac{\dif\bar H}{\dif t}=-\frac i \hbar\overline{[H,H]}=0,
\ee
which says energy is conserved in quantum mechanics.\\

All the above formalism in this subsection describes how state evolves with time during two measurements. But something different happens when an observation is made, during an experiment the state of a system jumps unpredictably to an eigenstate of the observable that was measured. This phenomenon is called \textit{the collapse of the wave function}. This implies that to examine the measurement process itself as a quantum mechanical evolution, we must consider the entire experimental setup, including the apparatus, as part of a single quantum system.

\subsection{Spin states, spin operators, and Pauli Matrices}
\textit{All possible spin states can be represented in a two dimensional vector space.}

\be
|A\ra=\al_u|u\ra+\al_k|d\ra,
\ee
where the $u$ and $d$ represents for pointing up and down when we measure spin along z-axis, and the orthogonality means if we get up we never get down, vice versa.\\
Now we choose A to be pointing left and right, considering that they're orthonormal, and it is equally likely to be up and down when measured along z, we write them as
\be\1\{\begin{split}
|r\ra&=\frac1 {\sqrt{2}}|u\ra+\frac1 {\sqrt{2}}|d\ra\\
|l\ra&=\frac1 {\sqrt{2}}|u\ra- \frac1 {\sqrt{2}}|d\ra.
\end{split}\2.\ee
And when we represent forward and backward, we must further take into account the equal likelihood of left and right when measured along x-axis, so we take the following form,
\be\1\{\begin{split}
|f\ra&=\frac1 {\sqrt{2}}|u\ra+\frac i {\sqrt{2}}|d\ra\\
|b\ra&=\frac1 {\sqrt{2}}|u\ra- \frac i {\sqrt{2}}|d\ra.
\end{split}\2.\ee
Notice that all the above choices have the same freedom by a phase factor $e^{i\theta}$.

We will use $\sig$ to denote spin operator. Measuring along z-axis gives us
\be\1\{\begin{split}
\sig_z |u\ra&=|u\ra\\
\sig_z |d\ra&=-|d\ra,
\end{split}\2.\ee
if we denote $|u\ra$ and $|d\ra$ as unit vectors as $\1(\ba{c}1\\0\ea\2)$ and $\1(\ba{c}0\\1\ea\2)$, we may figure out that
\be
\sig_z=\1(\ba{cc}1&0\\0&-1\ea\2).
\ee
Measuring along x-axis gives us
\be\1\{\begin{split}
\sig_x |r\ra&=|r\ra\\
\sig_x |l\ra&=-|l\ra,
\end{split}\2.\ee
if we denote $|r\ra$ and $|l\ra$ as unit vectors as $\1(\ba{c}\frac1{\sqrt{2}}\\\frac1{\sqrt{2}}\ea\2)$ and $\1(\ba{c}\frac1{\sqrt{2}}\\-\frac1{\sqrt{2}}\ea\2)$, we may figure out that
\be
\sig_x=\1(\ba{cc}0&1\\1&0\ea\2).
\ee
Measuring along y-axis gives us
\be\1\{\begin{split}
\sig_y |f\ra&=|f\ra\\
\sig_y |b\ra&=-|b\ra,
\end{split}\2.\ee
if we denote $|f\ra$ and $|b\ra$ as unit vectors as $\1(\ba{c}\frac1{\sqrt{2}}\\\frac i{\sqrt{2}}\ea\2)$ and $\1(\ba{c}\frac1{\sqrt{2}}\\-\frac i{\sqrt{2}}\ea\2)$, we may figure out that
\be
\sig_x=\1(\ba{cc}0&-i\\i&0\ea\2).
\ee
The matrix representations of $\sig_x$, $\sig_y$ and $\sig_z$ are called the \textit{Pauli Matrices}.\\
It is easy and useful to verify the commutation relations of components of spins,
\be
[\sig_j,\sig_k]=2i\ep_{jkl}\sig_l.
\ee

Now we may treat $\sig_x$, $\sig_y$ and $\sig_z$ as three components of $\sig$, thus $\sig$ can be viewed as a general vector, and it can be projected onto a unit vector $\hat n$ point any direction in space, so as to measure spin along that direction.
\be
\sig_n=\vec\sig\cdot\hat n=\sig_xn_x+\sig_yn_y+\sig_zn_z=\1(\ba{cc}n_z&n_x-in_y\\n_x+in_y&-n_z\ea\2)
\ee

If $\hat n$ lies x-z plane, we may write
\be\1\{\begin{split}
n_z&=\cos\theta\\
n_x&=\sin\theta\\
n_y&=0,
\end{split}\2.\ee
thus 
\be
\sig_n=\1(\ba{cc}\cos\theta&\sin\theta\\\sin\theta&-\cos\theta\ea\2),
\ee
its eigenvalues and corresponding eigenvectors are given by
\be\1\{\begin{split}
\lam_1=1, &\quad|\lam_1\ra=\1(\ba{c}\cos{\frac\theta 2}\\\sin{\frac\theta 2}\ea\2)\\
\lam_2=-1, &\quad|\lam_1\ra=\1(\ba{c}-\sin{\frac\theta 2}\\\cos{\frac\theta 2}\ea\2).
\end{split}\2.\ee
Now suppose we prepare a $|u\ra$ state, and we measure the probabilities of $+1$ and $-1$ along the $\hat n$ direction, we get
\be\1\{\begin{split}
P(+1)=&\la u|\lam_1\ra\la\lam_1|u\ra=\cos^2{\frac{\theta}{2}}\\
P(-1)=&\la u|\lam_2\ra\la\lam_2|u\ra=\sin^2{\frac{\theta}{2}}
\end{split}\2.\ee
Now we're ready to compute the average value of spin along the $n$ direction,
\be
\la \sig_n\ra=\sum_j \lam_j P(\lam_j)=\cos^2{\frac{\theta}{2}}-\sin^2{\frac{\theta}{2}}=\cos{\theta},
\ee
which agrees perfectly with our expectation.\\

To proceed, we come to an important theorem,\\

\textit{\textbf{The Spin-Polarization Principle:} Any state of a single spin is an eigenvector of some component of the spin.}\\

In other words, given any state
\be
|A\ra=\al_u|u\ra+\al_d|d\ra,
\ee
there exists some direction $\hat n$, such that
\be
\vec\sig\cdot\vec n|A\ra= |A\ra.
\ee
In physics language, we say that the states of a spin are characterized by a \textit{polarization vector}, and along that polarization vector the component of spin is predictably $+1$, assuming of course that you know the state-vector.\\ It follows that the expectation value of the spin along the direction $\hat n$ can be expressed as
\be
\la\sig_n\ra=\la \vec\sig\cdot\vec n\ra=1.
\ee

The energy of a spin in a magnetic field is given by
\be
H\sim \vec\sig\cdot\vec B=\sig_x B_x+\sig_y B_y+\sig_z B_z.
\ee
If the magnetic field lies along the z-axis, the Hamiltonian is proportional to $\sig_z$, in the following expression we'll absorb all the irrelevant numerical constants into a single constant $\omega$, so
\be 
H=\frac{\hbar\omega}{2} \sig_z,
\ee
where we kept $\frac\hbar 2$ for later convenience.\\
Now we want to find out how the expectation value of the spin varies with time, we can get
\be\begin{split}
\dot{\la\sig_x\ra}&=-\frac i \hbar \la[\sig_x,H]\ra=-\frac{i\omega} 2\la[\sig_x,\sig_z]\ra=-\om\la\sig_y\ra\\
\dot{\la\sig_y\ra}&=-\frac i \hbar \la[\sig_y,H]\ra=-\frac{i\omega} 2\la[\sig_y,\sig_z]\ra=\om\la\sig_x\ra\\
\dot{\la\sig_z\ra}&=-\frac i \hbar \la[\sig_z,H]\ra=-\frac{i\omega} 2\la[\sig_z,\sig_z]\ra=0
\end{split}\ee
This result implies that the 3-vector-operator $\vec\sig$ precesses like a gyroscope around the direction of the magnetic field. The precession is uniform, with angular velocity $\om$. To be specific, the expectation value for a $\sig_z$ measurement does not change with time, but the other two expectation values do change.















\end{document}